<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · MultiGridBarrierPETSc.jl</title><meta name="title" content="API Reference · MultiGridBarrierPETSc.jl"/><meta property="og:title" content="API Reference · MultiGridBarrierPETSc.jl"/><meta property="twitter:title" content="API Reference · MultiGridBarrierPETSc.jl"/><meta name="description" content="Documentation for MultiGridBarrierPETSc.jl."/><meta property="og:description" content="Documentation for MultiGridBarrierPETSc.jl."/><meta property="twitter:description" content="Documentation for MultiGridBarrierPETSc.jl."/><meta property="og:url" content="https://sloisel.github.io/MultiGridBarrierPETSc.jl/api/"/><meta property="twitter:url" content="https://sloisel.github.io/MultiGridBarrierPETSc.jl/api/"/><link rel="canonical" href="https://sloisel.github.io/MultiGridBarrierPETSc.jl/api/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MultiGridBarrierPETSc.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../installation/">Installation</a></li><li><a class="tocitem" href="../guide/">User Guide</a></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Initialization"><span>Initialization</span></a></li><li><a class="tocitem" href="#High-Level-API"><span>High-Level API</span></a></li><li><a class="tocitem" href="#Type-Conversion-API"><span>Type Conversion API</span></a></li><li><a class="tocitem" href="#Type-Mappings-Reference"><span>Type Mappings Reference</span></a></li><li><a class="tocitem" href="#Geometry-Structure"><span>Geometry Structure</span></a></li><li><a class="tocitem" href="#Solution-Structure"><span>Solution Structure</span></a></li><li><a class="tocitem" href="#MPI-and-IO-Utilities"><span>MPI and IO Utilities</span></a></li><li><a class="tocitem" href="#PETSc-Configuration"><span>PETSc Configuration</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#Integration-with-MultiGridBarrier"><span>Integration with MultiGridBarrier</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><p>This page provides detailed documentation for all exported functions in MultiGridBarrierPETSc.jl.</p><div class="admonition is-info" id="All-Functions-Are-Collective-26ad599f38f0a84e"><header class="admonition-header">All Functions Are Collective<a class="admonition-anchor" href="#All-Functions-Are-Collective-26ad599f38f0a84e" title="Permalink"></a></header><div class="admonition-body"><p>All functions documented here are <strong>MPI collective operations</strong>. Every MPI rank must call these functions together with the same parameters. Failure to do so will result in deadlock.</p></div></div><h2 id="Initialization"><a class="docs-heading-anchor" href="#Initialization">Initialization</a><a id="Initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Initialization" title="Permalink"></a></h2><p>This function must be called before using any other MultiGridBarrierPETSc functionality.</p><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.Init"><a class="docstring-binding" href="#MultiGridBarrierPETSc.Init"><code>MultiGridBarrierPETSc.Init</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">Init(; options=&quot;-MPIAIJ_ksp_type preonly -MPIAIJ_pc_type lu -MPIAIJ_pc_factor_mat_solver_type mumps&quot;)</code></pre><p><strong>Collective</strong></p><p>Initialize MultiGridBarrierPETSc by setting up MPI, PETSc, and solver options.</p><p>This function should be called once before using any MultiGridBarrierPETSc functionality. It will:</p><ol><li>Initialize MPI and PETSc if not already initialized</li><li>Configure PETSc solver options (default: use MUMPS direct solver for sparse matrices)</li></ol><p>The default options configure MPIAIJ (sparse) matrices to use:</p><ul><li><code>-ksp_type preonly</code>: Don&#39;t use iterative solver, just apply preconditioner</li><li><code>-pc_type lu</code>: Use LU factorization as preconditioner</li><li><code>-pc_factor_mat_solver_type mumps</code>: Use MUMPS sparse direct solver for the factorization</li></ul><p>Dense matrices (MPIDENSE) use PETSc&#39;s default dense LU solver.</p><p><strong>Arguments</strong></p><ul><li><code>options::String</code>: PETSc options string to set (default: MUMPS direct solver for sparse matrices)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">using MultiGridBarrierPETSc
MultiGridBarrierPETSc.Init()  # Use default MUMPS solver for sparse matrices

# Or with custom options:
MultiGridBarrierPETSc.Init(options=&quot;-MPIAIJ_ksp_type cg -MPIAIJ_pc_type jacobi&quot;)</code></pre><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><h2 id="High-Level-API"><a class="docs-heading-anchor" href="#High-Level-API">High-Level API</a><a id="High-Level-API-1"></a><a class="docs-heading-anchor-permalink" href="#High-Level-API" title="Permalink"></a></h2><p>These functions provide the simplest interface for solving problems with PETSc types.</p><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.fem2d_petsc"><a class="docstring-binding" href="#MultiGridBarrierPETSc.fem2d_petsc"><code>MultiGridBarrierPETSc.fem2d_petsc</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">fem2d_petsc(::Type{T}=Float64; kwargs...) where {T}</code></pre><p><strong>Collective</strong></p><p>Create a PETSc-based Geometry from fem2d parameters.</p><p>This function calls <code>fem2d(kwargs...)</code> to create a native geometry, then converts it to use PETSc distributed types (Mat and Vec) for distributed computing.</p><p>Note: Call <code>MultiGridBarrierPETSc.Init()</code> before using this function.</p><p><strong>Arguments</strong></p><ul><li><code>T::Type</code>: Element type for the geometry (default: Float64)</li><li><code>kwargs...</code>: Additional keyword arguments passed to <code>fem2d()</code></li></ul><p><strong>Returns</strong></p><p>A Geometry object with PETSc distributed types.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">MultiGridBarrierPETSc.Init()
g = fem2d_petsc(Float64; maxh=0.1)</code></pre><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.fem2d_petsc_solve"><a class="docstring-binding" href="#MultiGridBarrierPETSc.fem2d_petsc_solve"><code>MultiGridBarrierPETSc.fem2d_petsc_solve</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">fem2d_petsc_solve(::Type{T}=Float64; kwargs...) where {T}</code></pre><p><strong>Collective</strong></p><p>Solve a fem2d problem using amgb with PETSc distributed types.</p><p>This is a convenience function that combines <code>fem2d_petsc</code> and <code>amgb</code> into a single call. It creates a PETSc-based geometry and solves the barrier problem.</p><p><strong>Arguments</strong></p><ul><li><code>T::Type</code>: Element type for the geometry (default: Float64)</li><li><code>kwargs...</code>: Keyword arguments passed to both <code>fem2d_petsc</code> and <code>amgb</code><ul><li><code>maxh</code>: Maximum mesh size (passed to fem2d)</li><li><code>p</code>: Power parameter for the barrier (passed to amgb)</li><li><code>verbose</code>: Verbosity flag (passed to amgb)</li><li>Other arguments specific to fem2d or amgb</li></ul></li></ul><p><strong>Returns</strong></p><p>The solution object from <code>amgb</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">sol = fem2d_petsc_solve(Float64; maxh=0.1, p=2.0, verbose=true)
println(&quot;Solution norm: &quot;, norm(sol.z))</code></pre><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><h2 id="Type-Conversion-API"><a class="docs-heading-anchor" href="#Type-Conversion-API">Type Conversion API</a><a id="Type-Conversion-API-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Conversion-API" title="Permalink"></a></h2><p>These functions convert between native Julia types and PETSc distributed types.</p><h3 id="Geometry-Conversion"><a class="docs-heading-anchor" href="#Geometry-Conversion">Geometry Conversion</a><a id="Geometry-Conversion-1"></a><a class="docs-heading-anchor-permalink" href="#Geometry-Conversion" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.geometry_native_to_petsc"><a class="docstring-binding" href="#MultiGridBarrierPETSc.geometry_native_to_petsc"><code>MultiGridBarrierPETSc.geometry_native_to_petsc</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">geometry_native_to_petsc(g_native::Geometry{T, Matrix{T}, Vector{T}, SparseMatrixCSC{T,Int}, Discretization}) where {T, Discretization}</code></pre><p><strong>Collective</strong></p><p>Convert a native Geometry object (with Julia arrays) to use PETSc distributed types.</p><p>This is a collective operation. Each rank calls fem2d() to get the same native geometry, then this function converts:</p><ul><li>x::Matrix{T} -&gt; x::Mat{T, MPIDENSE}</li><li>w::Vector{T} -&gt; w::Vec{T, MPIDENSE}</li><li>operators[key]::SparseMatrixCSC{T,Int} -&gt; operators[key]::Mat{T, MPIAIJ}</li><li>subspaces[key][i]::SparseMatrixCSC{T,Int} -&gt; subspaces[key][i]::Mat{T, MPIAIJ}</li></ul><p>The MPIDENSE prefix indicates dense storage (for geometry data and weights), while MPIAIJ indicates sparse storage (for operators and subspace matrices).</p><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.geometry_petsc_to_native"><a class="docstring-binding" href="#MultiGridBarrierPETSc.geometry_petsc_to_native"><code>MultiGridBarrierPETSc.geometry_petsc_to_native</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">geometry_petsc_to_native(g_petsc::Geometry{T, Mat{T,XPrefix}, Vec{T,WPrefix}, Mat{T,MPrefix}, Discretization}) where {T, XPrefix, WPrefix, MPrefix, Discretization}</code></pre><p><strong>Collective</strong></p><p>Convert a PETSc Geometry object (with distributed PETSc types) back to native Julia arrays.</p><p>This is a collective operation. This function converts:</p><ul><li>x::Mat{T, MPIDENSE} -&gt; x::Matrix{T}</li><li>w::Vec{T, MPIDENSE} -&gt; w::Vector{T}</li><li>operators[key]::Mat{T, MPIAIJ} -&gt; operators[key]::SparseMatrixCSC{T,Int}</li><li>subspaces[key][i]::Mat{T, MPIAIJ} -&gt; subspaces[key][i]::SparseMatrixCSC{T,Int}</li></ul><p>Uses SafePETSc.J() which automatically handles dense vs sparse conversion based on the Mat&#39;s storage type.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><h3 id="Solution-Conversion"><a class="docs-heading-anchor" href="#Solution-Conversion">Solution Conversion</a><a id="Solution-Conversion-1"></a><a class="docs-heading-anchor-permalink" href="#Solution-Conversion" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="MultiGridBarrierPETSc.sol_petsc_to_native"><a class="docstring-binding" href="#MultiGridBarrierPETSc.sol_petsc_to_native"><code>MultiGridBarrierPETSc.sol_petsc_to_native</code></a> — <span class="docstring-category">Function</span></summary><div><pre><code class="language-julia hljs">sol_petsc_to_native(sol_petsc::AMGBSOL{T, Mat{T,XPrefix}, Vec{T,WPrefix}, Mat{T,MPrefix}, Discretization}) where {T, XPrefix, WPrefix, MPrefix, Discretization}</code></pre><p><strong>Collective</strong></p><p>Convert an AMGBSOL solution object from PETSc types back to native Julia types.</p><p>This is a collective operation that performs a deep conversion of the solution structure:</p><ul><li>z: Mat{T,Prefix} -&gt; Matrix{T} or Vec{T,Prefix} -&gt; Vector{T} (depending on the type)</li><li>SOL_feasibility: NamedTuple with PETSc types -&gt; NamedTuple with native types</li><li>SOL_main: NamedTuple with PETSc types -&gt; NamedTuple with native types</li><li>geometry: Geometry with PETSc types -&gt; Geometry with native types</li></ul><p>Uses SafePETSc.J() which automatically handles dense vs sparse conversion based on the Mat&#39;s storage type.</p><a class="docs-sourcelink" target="_blank" href="https://github.com/sloisel/MultiGridBarrierPETSc.jl">source</a></div></details></article><h2 id="Type-Mappings-Reference"><a class="docs-heading-anchor" href="#Type-Mappings-Reference">Type Mappings Reference</a><a id="Type-Mappings-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Mappings-Reference" title="Permalink"></a></h2><h3 id="Native-to-PETSc-Conversions"><a class="docs-heading-anchor" href="#Native-to-PETSc-Conversions">Native to PETSc Conversions</a><a id="Native-to-PETSc-Conversions-1"></a><a class="docs-heading-anchor-permalink" href="#Native-to-PETSc-Conversions" title="Permalink"></a></h3><p>When converting from native Julia types to PETSc distributed types:</p><table><tr><th style="text-align: right">Native Type</th><th style="text-align: right">PETSc Type</th><th style="text-align: right">PETSc Prefix</th><th style="text-align: right">Usage</th></tr><tr><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right"><code>Mat{T, MPIDENSE}</code></td><td style="text-align: right">MPIDENSE</td><td style="text-align: right">Geometry coordinates, dense operators</td></tr><tr><td style="text-align: right"><code>Vector{T}</code></td><td style="text-align: right"><code>Vec{T, MPIDENSE}</code></td><td style="text-align: right">MPIDENSE</td><td style="text-align: right">Weights, dense vectors</td></tr><tr><td style="text-align: right"><code>SparseMatrixCSC{T,Int}</code></td><td style="text-align: right"><code>Mat{T, MPIAIJ}</code></td><td style="text-align: right">MPIAIJ</td><td style="text-align: right">Sparse operators, subspace matrices</td></tr></table><h3 id="PETSc-to-Native-Conversions"><a class="docs-heading-anchor" href="#PETSc-to-Native-Conversions">PETSc to Native Conversions</a><a id="PETSc-to-Native-Conversions-1"></a><a class="docs-heading-anchor-permalink" href="#PETSc-to-Native-Conversions" title="Permalink"></a></h3><p>When converting from PETSc distributed types back to native Julia types:</p><table><tr><th style="text-align: right">PETSc Type</th><th style="text-align: right">Native Type</th><th style="text-align: right">Conversion Method</th></tr><tr><td style="text-align: right"><code>Mat{T, MPIDENSE}</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right"><code>SafePETSc.J()</code></td></tr><tr><td style="text-align: right"><code>Mat{T, MPIAIJ}</code></td><td style="text-align: right"><code>SparseMatrixCSC{T,Int}</code></td><td style="text-align: right"><code>SafePETSc.J()</code></td></tr><tr><td style="text-align: right"><code>Vec{T, MPIDENSE}</code></td><td style="text-align: right"><code>Vector{T}</code></td><td style="text-align: right"><code>SafePETSc.J()</code></td></tr></table><h2 id="Geometry-Structure"><a class="docs-heading-anchor" href="#Geometry-Structure">Geometry Structure</a><a id="Geometry-Structure-1"></a><a class="docs-heading-anchor-permalink" href="#Geometry-Structure" title="Permalink"></a></h2><p>The <code>Geometry</code> type from MultiGridBarrier is parameterized by its storage types:</p><p><strong>Native Geometry:</strong></p><pre><code class="language-julia hljs">Geometry{T, Matrix{T}, Vector{T}, SparseMatrixCSC{T,Int}, Discretization}</code></pre><p><strong>PETSc Geometry:</strong></p><pre><code class="language-julia hljs">Geometry{T, Mat{T,MPIDENSE}, Vec{T,MPIDENSE}, Mat{T,MPIAIJ}, Discretization}</code></pre><h3 id="Fields"><a class="docs-heading-anchor" href="#Fields">Fields</a><a id="Fields-1"></a><a class="docs-heading-anchor-permalink" href="#Fields" title="Permalink"></a></h3><ul><li><strong><code>discretization</code></strong>: Discretization information (domain, mesh, etc.)</li><li><strong><code>x</code></strong>: Geometry coordinates (Matrix or Mat)</li><li><strong><code>w</code></strong>: Quadrature weights (Vector or Vec)</li><li><strong><code>operators</code></strong>: Dictionary of operators (id, laplacian, mass, etc.)</li><li><strong><code>subspaces</code></strong>: Dictionary of subspace projection matrices</li><li><strong><code>refine</code></strong>: Vector of refinement matrices (coarse → fine)</li><li><strong><code>coarsen</code></strong>: Vector of coarsening matrices (fine → coarse)</li></ul><h2 id="Solution-Structure"><a class="docs-heading-anchor" href="#Solution-Structure">Solution Structure</a><a id="Solution-Structure-1"></a><a class="docs-heading-anchor-permalink" href="#Solution-Structure" title="Permalink"></a></h2><p>The <code>AMGBSOL</code> type from MultiGridBarrier contains the complete solution:</p><h3 id="Fields-2"><a class="docs-heading-anchor" href="#Fields-2">Fields</a><a class="docs-heading-anchor-permalink" href="#Fields-2" title="Permalink"></a></h3><ul><li><strong><code>z</code></strong>: Solution matrix/vector</li><li><strong><code>SOL_feasibility</code></strong>: NamedTuple with feasibility phase information</li><li><strong><code>SOL_main</code></strong>: NamedTuple with main solve information<ul><li><code>objective</code>: Final objective function value</li><li><code>primal_residual</code>: Primal feasibility residual</li><li><code>dual_residual</code>: Dual feasibility residual</li></ul></li><li><strong><code>log</code></strong>: Vector of iteration logs</li><li><strong><code>geometry</code></strong>: The geometry used for solving</li></ul><h2 id="MPI-and-IO-Utilities"><a class="docs-heading-anchor" href="#MPI-and-IO-Utilities">MPI and IO Utilities</a><a id="MPI-and-IO-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#MPI-and-IO-Utilities" title="Permalink"></a></h2><h3 id="SafePETSc.io0()"><a class="docs-heading-anchor" href="#SafePETSc.io0()">SafePETSc.io0()</a><a id="SafePETSc.io0()-1"></a><a class="docs-heading-anchor-permalink" href="#SafePETSc.io0()" title="Permalink"></a></h3><p>Returns an IO stream that only writes on rank 0:</p><pre><code class="language-julia hljs">println(io0(), &quot;This prints once from rank 0&quot;)
println(io0(), my_petsc_vec)  # Collective show() of Vec</code></pre><h3 id="MPI-Rank-Information"><a class="docs-heading-anchor" href="#MPI-Rank-Information">MPI Rank Information</a><a id="MPI-Rank-Information-1"></a><a class="docs-heading-anchor-permalink" href="#MPI-Rank-Information" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MPI

rank = MPI.Comm_rank(MPI.COMM_WORLD)  # Current rank (0 to nranks-1)
nranks = MPI.Comm_size(MPI.COMM_WORLD)  # Total number of ranks</code></pre><h2 id="PETSc-Configuration"><a class="docs-heading-anchor" href="#PETSc-Configuration">PETSc Configuration</a><a id="PETSc-Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#PETSc-Configuration" title="Permalink"></a></h2><h3 id="MUMPS-Solver"><a class="docs-heading-anchor" href="#MUMPS-Solver">MUMPS Solver</a><a id="MUMPS-Solver-1"></a><a class="docs-heading-anchor-permalink" href="#MUMPS-Solver" title="Permalink"></a></h3><p>The <code>Init()</code> function automatically configures PETSc to use MUMPS for sparse matrices:</p><pre><code class="language-julia hljs"># Equivalent PETSc options set automatically:
# -MPIAIJ_ksp_type preonly          # No iterative solver, just direct solve
# -MPIAIJ_pc_type lu                # LU factorization
# -MPIAIJ_pc_factor_mat_solver_type mumps  # Use MUMPS for factorization</code></pre><p><strong>Matrix Type Configuration:</strong></p><ul><li><strong>Sparse matrices (MPIAIJ)</strong>: Use MUMPS direct solver for exact solves</li><li><strong>Dense matrices (MPIDENSE)</strong>: Use PETSc&#39;s default dense LU solver</li></ul><p>This ensures exact direct solves for linear systems in the barrier method&#39;s Newton iterations.</p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><h3 id="Type-Conversion-Round-Trip"><a class="docs-heading-anchor" href="#Type-Conversion-Round-Trip">Type Conversion Round-Trip</a><a id="Type-Conversion-Round-Trip-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Conversion-Round-Trip" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MultiGridBarrierPETSc
using MultiGridBarrier
using LinearAlgebra
MultiGridBarrierPETSc.Init()

# Create native geometry
g_native = fem2d(; maxh=0.3)

# Convert to PETSc
g_petsc = geometry_native_to_petsc(g_native)

# Solve with PETSc types
sol_petsc = amgb(g_petsc; p=2.0)

# Convert back to native
sol_native = sol_petsc_to_native(sol_petsc)
g_back = geometry_petsc_to_native(g_petsc)

# Verify round-trip accuracy
@assert norm(g_native.x - g_back.x) &lt; 1e-10
@assert norm(g_native.w - g_back.w) &lt; 1e-10</code></pre><h3 id="Accessing-Operator-Matrices"><a class="docs-heading-anchor" href="#Accessing-Operator-Matrices">Accessing Operator Matrices</a><a id="Accessing-Operator-Matrices-1"></a><a class="docs-heading-anchor-permalink" href="#Accessing-Operator-Matrices" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Native geometry
g_native = fem2d(; maxh=0.2)
lap_native = g_native.operators[:laplacian]  # SparseMatrixCSC

# PETSc geometry
g_petsc = geometry_native_to_petsc(g_native)
lap_petsc = g_petsc.operators[:laplacian]  # Mat{Float64, MPIAIJ}

# Convert back if needed
lap_back = SafePETSc.J(lap_petsc)  # SparseMatrixCSC</code></pre><h2 id="Integration-with-MultiGridBarrier"><a class="docs-heading-anchor" href="#Integration-with-MultiGridBarrier">Integration with MultiGridBarrier</a><a id="Integration-with-MultiGridBarrier-1"></a><a class="docs-heading-anchor-permalink" href="#Integration-with-MultiGridBarrier" title="Permalink"></a></h2><p>All MultiGridBarrier functions work seamlessly with PETSc types:</p><pre><code class="language-julia hljs">using MultiGridBarrier: amgb, amgb_solve

# Create PETSc geometry
g = fem2d_petsc(Float64; L=3)

# Use MultiGridBarrier functions directly
sol = amgb(g; p=1.0, verbose=true)
sol = amgb_solve(g; p=1.5, maxit=50, tol=1e-10)</code></pre><p>The package extends MultiGridBarrier&#39;s internal API (<code>amgb_zeros</code>, <code>amgb_hcat</code>, <code>amgb_diag</code>, etc.) to work with PETSc types automatically.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../guide/">« User Guide</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Wednesday 19 November 2025 23:10">Wednesday 19 November 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
